# Open LLM for Multimodal

Non-Multimodal LLM: https://github.com/eugeneyan/open-llms

## Open Model

| Language Model | Company/Org                                                                        | Release Date | Github/Huggingface                                                                                                                            | Paper/Blog                                                                                                                                                                                              | Function                                                                                                                                       | Modal                                                   | Licence             |
|----------------|------------------------------------------------------------------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------|---------------------|
| ImageBind      | FAIR, Meta AI                                                                      | 2023.05      | [facebookresearch/ImageBind](https://github.com/facebookresearch/ImageBind)                                                                   | [ImageBind: One Embedding Space To Bind Them All](https://arxiv.org/abs/2305.05665) <br> [ImageBind: Holistic AI learning across six modalities](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/) | cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation                                              | image/video, text, audio, depth, IMU, and thermal images | CC BY-NC-SA 4.0     | 
| BLIP-2         | Salesforce                                                                         | 2023.01      | [blip2](https://github.com/salesforce/LAVIS/tree/main/projects/blip2) <br/>  [hf/blip-2](https://huggingface.co/models?other=blip-2)          | [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)                                                              | image-to-text,feature extraction,image-text match                                                                                              | image,text                                              | MIT                 |
| MiniGPT-4      | King Abdullah University of Science and Technology                                 | 2023.05      | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) <br/> [hf/Vision-CAIR/MiniGPT-4](https://huggingface.co/Vision-CAIR/MiniGPT-4) | [MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models](https://arxiv.org/abs/2304.10592)  | writing stories and poems inspired by given images, providing solutions to problems shown in images, teaching users how to cook based on food photos, etc. | image,text                                              | BSD 3-Clause License |
| LLaVA | University of Wisconsin-Madison <br/> Microsoft Research <br/> Columbia University | 2023.05      | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) <br/> [LLaVA-13b-delta-v0](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0) | [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) | general-purpose visual and language understanding | image,text   | Apache-2.0 | 


## Open Data

| Name | Release Date | Function | Paper/Blog | Dataset                            | Samples | License     |
| --- |--------------|----------|------------|------------------------------------|---------|-------------| 
| LLaVA-Instruct-150K | 2023.04      | IFT | [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485)  | [liuhaotian/LLaVA-Instruct-150K](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) | 150K    | CC BY-SA-4.0 | 
| LAION-400M | 2021.08 | PreTrain | [LAION-400-MILLION OPEN DATASET](https://laion.ai/blog/laion-400-open-dataset) | [laion/laion400m](https://huggingface.co/datasets/laion/laion400m) | 400M | CC BY-SA-4.0 |